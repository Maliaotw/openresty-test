2019/06/12 10:45:36 [error] 13598#3090086: *1 [lua] content_by_lua(nginx.conf:177):5: num:55, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:45:36 [error] 13598#3090086: *1 [lua] content_by_lua(nginx.conf:177):8:  object:nil, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:51:50 [error] 13994#3097090: *1 [lua] content_by_lua(nginx.conf:177):5: num:55, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:51:50 [error] 13994#3097090: *1 [lua] content_by_lua(nginx.conf:177):8:  object:nil, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:52:29 [notice] 14444#3100207: using the "kqueue" event method
2019/06/12 10:52:29 [notice] 14444#3100207: openresty/1.15.8.1
2019/06/12 10:52:29 [notice] 14444#3100207: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 10:52:29 [notice] 14444#3100207: OS: Darwin 18.6.0
2019/06/12 10:52:29 [notice] 14444#3100207: hw.ncpu: 8
2019/06/12 10:52:29 [notice] 14444#3100207: net.inet.tcp.sendspace: 131072
2019/06/12 10:52:29 [notice] 14444#3100207: kern.ipc.somaxconn: 128
2019/06/12 10:52:29 [notice] 14444#3100207: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 10:52:29 [notice] 14445#3100209: start worker processes
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14446
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14447
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14449
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14450
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14451
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14453
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14454
2019/06/12 10:52:29 [notice] 14445#3100209: start worker process 14455
2019/06/12 10:52:29 [notice] 14445#3100209: signal 23 (SIGIO) received
2019/06/12 10:52:29 [notice] 14445#3100209: signal 23 (SIGIO) received
2019/06/12 10:52:29 [notice] 14445#3100209: signal 23 (SIGIO) received
2019/06/12 10:52:32 [error] 14451#3100215: *1 [lua] content_by_lua(nginx.conf:177):5: num:55, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:52:32 [info] 14451#3100215: *1 [lua] content_by_lua(nginx.conf:177):6:  string:string, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:52:32 [notice] 14451#3100215: *1 [lua] content_by_lua(nginx.conf:177):7: i am print, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:52:32 [error] 14451#3100215: *1 [lua] content_by_lua(nginx.conf:177):8:  object:nil, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 10:52:32 [info] 14451#3100215: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 11:20:32 [notice] 28425#3161062: using the "kqueue" event method
2019/06/12 11:20:32 [notice] 28425#3161062: openresty/1.15.8.1
2019/06/12 11:20:32 [notice] 28425#3161062: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 11:20:32 [notice] 28425#3161062: OS: Darwin 18.6.0
2019/06/12 11:20:32 [notice] 28425#3161062: hw.ncpu: 8
2019/06/12 11:20:32 [notice] 28425#3161062: net.inet.tcp.sendspace: 131072
2019/06/12 11:20:32 [notice] 28425#3161062: kern.ipc.somaxconn: 128
2019/06/12 11:20:32 [notice] 28425#3161062: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 11:20:32 [notice] 28426#3161065: start worker processes
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28427
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28428
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28429
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28430
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28432
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28433
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28434
2019/06/12 11:20:32 [notice] 28426#3161065: start worker process 28435
2019/06/12 11:20:32 [notice] 28426#3161065: signal 23 (SIGIO) received
2019/06/12 11:20:32 [notice] 28426#3161065: signal 23 (SIGIO) received from 28433
2019/06/12 11:20:32 [notice] 28426#3161065: signal 23 (SIGIO) received
2019/06/12 11:20:32 [notice] 28426#3161065: signal 23 (SIGIO) received from 28434
2019/06/12 11:20:55 [error] 28435#3161074: *1 "/Users/maliao/openresty-test/html/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:81"
2019/06/12 11:20:55 [error] 28435#3161074: *1 failed to run log_by_lua*: log_by_lua(nginx.conf:214):2: module 'resty.logger.socket' not found:
	no field package.preload['resty.logger.socket']
	no file '/Users/maliao/lua-resty-logger-sockett/lib/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket/init.lua'
	no file './resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/logger/socket.lua'
	no file '/usr/local/share/lua/5.1/resty/logger/socket.lua'
	no file '/usr/local/share/lua/5.1/resty/logger/socket/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/logger/socket/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket.so'
	no file './resty/logger/socket.so'
	no file '/usr/local/lib/lua/5.1/resty/logger/socket.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/logger/socket.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
	[C]: in function 'require'
	log_by_lua(nginx.conf:214):2: in main chunk while logging request, client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:81"
2019/06/12 11:20:55 [info] 28435#3161074: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 11:21:14 [error] 28433#3161072: *2 "/Users/maliao/openresty-test/html/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:81"
2019/06/12 11:21:14 [error] 28433#3161072: *2 failed to run log_by_lua*: log_by_lua(nginx.conf:214):2: module 'resty.logger.socket' not found:
	no field package.preload['resty.logger.socket']
	no file '/Users/maliao/lua-resty-logger-sockett/lib/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket/init.lua'
	no file './resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/logger/socket.lua'
	no file '/usr/local/share/lua/5.1/resty/logger/socket.lua'
	no file '/usr/local/share/lua/5.1/resty/logger/socket/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/logger/socket.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/logger/socket/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/logger/socket.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/logger/socket.so'
	no file './resty/logger/socket.so'
	no file '/usr/local/lib/lua/5.1/resty/logger/socket.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/logger/socket.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
	[C]: in function 'require'
	log_by_lua(nginx.conf:214):2: in main chunk while logging request, client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:81"
2019/06/12 11:21:14 [info] 28433#3161072: *2 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 11:28:27 [error] 28925#3172539: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:28:38 [error] 28928#3172542: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:28:49 [error] 28924#3172538: *3 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:28:54 [error] 28930#3172545: *4 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "POST /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:28:56 [error] 28927#3172541: *5 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "POST /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:29:29 [error] 28928#3172542: *6 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:29:29 [error] 28930#3172545: *8 open() "/Users/maliao/openresty-test/html/favicon.ico" failed (2: No such file or directory), client: 127.0.0.1, server: , request: "GET /favicon.ico HTTP/1.1", host: "127.0.0.1:82", referrer: "http://127.0.0.1:82/addition"
2019/06/12 11:29:35 [error] 28930#3172545: *8 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'b' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition?a=1 HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:35:30 [error] 28927#3172541: *13 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'a' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:36:23 [error] 28925#3172539: *14 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'b' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition?a=1 HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:36:39 [error] 28922#3172536: *15 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:226):3: attempt to perform arithmetic on field 'b' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:226): in main chunk, client: 127.0.0.1, server: , request: "GET /addition?a=1& HTTP/1.1", host: "127.0.0.1:82"
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:07 [emerg] 33391#3217972: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:16 [emerg] 33734#3218547: still could not bind()
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 11:53:21 [emerg] 33906#3218810: still could not bind()
2019/06/12 11:53:53 [error] 33648#3218418: *1 "/Users/maliao/openresty-test/html/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:84"
2019/06/12 11:56:05 [error] 33642#3218412: *2 open() "/Users/maliao/openresty-test/html/addition" failed (2: No such file or directory), client: 127.0.0.1, server: , request: "GET /addition?a=1&b=2 HTTP/1.1", host: "127.0.0.1:84"
2019/06/12 12:02:06 [error] 34497#3233657: *1 open() "/Users/maliao/openresty-test/html/addition" failed (2: No such file or directory), client: 127.0.0.1, server: , request: "GET /addition?a=1&b=2 HTTP/1.1", host: "127.0.0.1:84"
2019/06/12 12:03:18 [error] 34864#3235935: *1 open() "/Users/maliao/openresty-test/html/addition" failed (2: No such file or directory), client: 127.0.0.1, server: , request: "GET /addition?a=1&b=2 HTTP/1.1", host: "127.0.0.1:83"
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 13:52:06 [emerg] 37434#3369314: still could not bind()
2019/06/12 14:06:20 [error] 37998#3383892: *1 [lua] content_by_lua(nginx.conf:180):5: num:55, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 14:06:20 [error] 37998#3383892: *1 [lua] content_by_lua(nginx.conf:180):8:  object:nil, client: 127.0.0.1, server: localhost, request: "GET / HTTP/1.1", host: "127.0.0.1"
2019/06/12 14:06:26 [error] 38000#3383894: *2 [lua] content_by_lua(nginx.conf:180):5: num:55, client: 127.0.0.1, server: localhost, request: "GET /sum HTTP/1.1", host: "127.0.0.1"
2019/06/12 14:06:26 [error] 38000#3383894: *2 [lua] content_by_lua(nginx.conf:180):8:  object:nil, client: 127.0.0.1, server: localhost, request: "GET /sum HTTP/1.1", host: "127.0.0.1"
2019/06/12 14:06:41 [error] 37994#3383888: *3 open() "/Users/maliao/openresty-test/html/sum" failed (2: No such file or directory), client: 127.0.0.1, server: , request: "GET /sum HTTP/1.1", host: "127.0.0.1:83"
2019/06/12 14:16:33 [notice] 38857#3398650: using the "kqueue" event method
2019/06/12 14:16:33 [notice] 38857#3398650: openresty/1.15.8.1
2019/06/12 14:16:33 [notice] 38857#3398650: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:16:33 [notice] 38857#3398650: OS: Darwin 18.6.0
2019/06/12 14:16:33 [notice] 38857#3398650: hw.ncpu: 8
2019/06/12 14:16:33 [notice] 38857#3398650: net.inet.tcp.sendspace: 131072
2019/06/12 14:16:33 [notice] 38857#3398650: kern.ipc.somaxconn: 128
2019/06/12 14:16:33 [notice] 38857#3398650: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:16:33 [notice] 38858#3398652: start worker processes
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38859
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38860
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38861
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38863
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38864
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38865
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38867
2019/06/12 14:16:33 [notice] 38858#3398652: start worker process 38868
2019/06/12 14:16:33 [notice] 38858#3398652: signal 23 (SIGIO) received
2019/06/12 14:16:33 [notice] 38858#3398652: signal 23 (SIGIO) received from 38867
2019/06/12 14:16:45 [notice] 38865#3398659: *1 [lua] access_by_lua(nginx.conf:287):5: 127.0.0.1, client: 127.0.0.1, server: localhost, request: "GET /sum HTTP/1.1", host: "127.0.0.1:84"
2019/06/12 14:16:45 [info] 38865#3398659: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:17:44 [notice] 39135#3400686: using the "kqueue" event method
2019/06/12 14:17:44 [notice] 39135#3400686: openresty/1.15.8.1
2019/06/12 14:17:44 [notice] 39135#3400686: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:17:44 [notice] 39135#3400686: OS: Darwin 18.6.0
2019/06/12 14:17:44 [notice] 39135#3400686: hw.ncpu: 8
2019/06/12 14:17:44 [notice] 39135#3400686: net.inet.tcp.sendspace: 131072
2019/06/12 14:17:44 [notice] 39135#3400686: kern.ipc.somaxconn: 128
2019/06/12 14:17:44 [notice] 39135#3400686: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:17:44 [notice] 39136#3400699: start worker processes
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39137
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39138
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39139
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39140
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39141
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39142
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39144
2019/06/12 14:17:44 [notice] 39136#3400699: start worker process 39145
2019/06/12 14:17:44 [notice] 39136#3400699: signal 23 (SIGIO) received
2019/06/12 14:17:44 [notice] 39136#3400699: signal 23 (SIGIO) received from 39144
2019/06/12 14:17:46 [notice] 39144#3400712: *1 [lua] access_by_lua(nginx.conf:288):5: test, client: 127.0.0.1, server: localhost, request: "GET /sum HTTP/1.1", host: "127.0.0.1:84"
2019/06/12 14:17:46 [notice] 39144#3400712: *1 [lua] access_by_lua(nginx.conf:288):6: 127.0.0.1, client: 127.0.0.1, server: localhost, request: "GET /sum HTTP/1.1", host: "127.0.0.1:84"
2019/06/12 14:17:46 [info] 39144#3400712: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:18:39 [notice] 39140#3400704: *2 [lua] access_by_lua(nginx.conf:288):5: test, client: 172.16.10.189, server: localhost, request: "GET /sum HTTP/1.1", host: "172.16.10.189:84"
2019/06/12 14:18:39 [notice] 39140#3400704: *2 [lua] access_by_lua(nginx.conf:288):6: 172.16.10.189, client: 172.16.10.189, server: localhost, request: "GET /sum HTTP/1.1", host: "172.16.10.189:84"
2019/06/12 14:18:39 [info] 39140#3400704: *2 kevent() reported that client 172.16.10.189 closed keepalive connection
2019/06/12 14:19:31 [notice] 39137#3400701: *3 [lua] access_by_lua(nginx.conf:288):5: test, client: 172.16.10.188, server: localhost, request: "GET /sum HTTP/1.1", host: "172.16.10.189:84"
2019/06/12 14:19:31 [notice] 39137#3400701: *3 [lua] access_by_lua(nginx.conf:288):6: 172.16.10.188, client: 172.16.10.188, server: localhost, request: "GET /sum HTTP/1.1", host: "172.16.10.189:84"
2019/06/12 14:19:31 [error] 39145#3400714: *4 open() "/Users/maliao/openresty-test/html/favicon.ico" failed (2: No such file or directory), client: 172.16.10.188, server: localhost, request: "GET /favicon.ico HTTP/1.1", host: "172.16.10.189:84", referrer: "http://172.16.10.189:84/sum"
2019/06/12 14:20:01 [info] 39137#3400701: *3 kevent() reported that client 172.16.10.188 closed keepalive connection
2019/06/12 14:20:01 [info] 39145#3400714: *4 kevent() reported that client 172.16.10.188 closed keepalive connection
2019/06/12 14:42:10 [notice] 39929#3436123: using the "kqueue" event method
2019/06/12 14:42:10 [notice] 39929#3436123: openresty/1.15.8.1
2019/06/12 14:42:10 [notice] 39929#3436123: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:42:10 [notice] 39929#3436123: OS: Darwin 18.6.0
2019/06/12 14:42:10 [notice] 39929#3436123: hw.ncpu: 8
2019/06/12 14:42:10 [notice] 39929#3436123: net.inet.tcp.sendspace: 131072
2019/06/12 14:42:10 [notice] 39929#3436123: kern.ipc.somaxconn: 128
2019/06/12 14:42:10 [notice] 39929#3436123: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:42:10 [notice] 39930#3436125: start worker processes
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39931
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39932
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39933
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39934
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39936
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39937
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39938
2019/06/12 14:42:10 [notice] 39930#3436125: start worker process 39939
2019/06/12 14:42:10 [notice] 39930#3436125: signal 23 (SIGIO) received
2019/06/12 14:42:10 [notice] 39930#3436125: signal 23 (SIGIO) received from 39938
2019/06/12 14:50:39 [notice] 41147#3452134: using the "kqueue" event method
2019/06/12 14:50:39 [notice] 41147#3452134: openresty/1.15.8.1
2019/06/12 14:50:39 [notice] 41147#3452134: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:50:39 [notice] 41147#3452134: OS: Darwin 18.6.0
2019/06/12 14:50:39 [notice] 41147#3452134: hw.ncpu: 8
2019/06/12 14:50:39 [notice] 41147#3452134: net.inet.tcp.sendspace: 131072
2019/06/12 14:50:39 [notice] 41147#3452134: kern.ipc.somaxconn: 128
2019/06/12 14:50:39 [notice] 41147#3452134: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:50:39 [notice] 41148#3452149: start worker processes
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41149
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41150
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41151
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41152
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41153
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41155
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41156
2019/06/12 14:50:39 [notice] 41148#3452149: start worker process 41157
2019/06/12 14:50:39 [notice] 41148#3452149: signal 23 (SIGIO) received
2019/06/12 14:50:39 [notice] 41148#3452149: signal 23 (SIGIO) received from 41155
2019/06/12 14:50:39 [notice] 41148#3452149: signal 23 (SIGIO) received
2019/06/12 14:50:39 [notice] 41148#3452149: signal 23 (SIGIO) received from 41156
2019/06/12 14:51:43 [warn] 41151#3452152: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:307):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:51:43 [info] 41151#3452152: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:51:53 [warn] 41156#3452157: *2 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:307):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:51:53 [info] 41156#3452157: *2 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:52:51 [notice] 41692#3456183: using the "kqueue" event method
2019/06/12 14:52:51 [notice] 41692#3456183: openresty/1.15.8.1
2019/06/12 14:52:51 [notice] 41692#3456183: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:52:51 [notice] 41692#3456183: OS: Darwin 18.6.0
2019/06/12 14:52:51 [notice] 41692#3456183: hw.ncpu: 8
2019/06/12 14:52:51 [notice] 41692#3456183: net.inet.tcp.sendspace: 131072
2019/06/12 14:52:51 [notice] 41692#3456183: kern.ipc.somaxconn: 128
2019/06/12 14:52:51 [notice] 41692#3456183: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:52:51 [notice] 41693#3456184: start worker processes
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41694
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41695
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41696
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41697
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41698
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41700
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41701
2019/06/12 14:52:51 [notice] 41693#3456184: start worker process 41702
2019/06/12 14:52:51 [notice] 41693#3456184: signal 23 (SIGIO) received
2019/06/12 14:52:51 [notice] 41693#3456184: signal 23 (SIGIO) received from 41700
2019/06/12 14:52:51 [notice] 41693#3456184: signal 23 (SIGIO) received from 41701
2019/06/12 14:52:56 [warn] 41702#3456193: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:307):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:52:56 [info] 41702#3456193: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:53:15 [warn] 41700#3456191: *2 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:307):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:53:15 [info] 41700#3456191: *2 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:53:52 [notice] 42053#3458227: using the "kqueue" event method
2019/06/12 14:53:52 [notice] 42053#3458227: openresty/1.15.8.1
2019/06/12 14:53:52 [notice] 42053#3458227: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:53:52 [notice] 42053#3458227: OS: Darwin 18.6.0
2019/06/12 14:53:52 [notice] 42053#3458227: hw.ncpu: 8
2019/06/12 14:53:52 [notice] 42053#3458227: net.inet.tcp.sendspace: 131072
2019/06/12 14:53:52 [notice] 42053#3458227: kern.ipc.somaxconn: 128
2019/06/12 14:53:52 [notice] 42053#3458227: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:53:52 [notice] 42054#3458232: start worker processes
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42055
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42056
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42057
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42058
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42059
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42061
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42062
2019/06/12 14:53:52 [notice] 42054#3458232: start worker process 42063
2019/06/12 14:53:53 [notice] 42054#3458232: signal 23 (SIGIO) received
2019/06/12 14:53:53 [notice] 42054#3458232: signal 23 (SIGIO) received
2019/06/12 14:53:53 [notice] 42054#3458232: signal 23 (SIGIO) received from 42062
2019/06/12 14:53:54 [warn] 42062#3458240: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:53:54 [error] 42062#3458240: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:309):3: bad argument #1 to 'print' (expected table to have __tostring metamethod)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:309):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:54:54 [notice] 42243#3459855: try again to bind() after 500ms
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:54:54 [notice] 42243#3459855: try again to bind() after 500ms
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:54:54 [emerg] 42243#3459855: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:54:54 [notice] 42243#3459855: try again to bind() after 500ms
2019/06/12 14:54:57 [warn] 42061#3458239: *2 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:54:57 [error] 42061#3458239: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:309):3: bad argument #1 to 'print' (expected table to have __tostring metamethod)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:309):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:54:58 [notice] 42416#3460124: try again to bind() after 500ms
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:54:58 [notice] 42416#3460124: try again to bind() after 500ms
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:54:58 [emerg] 42416#3460124: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:54:58 [notice] 42416#3460124: try again to bind() after 500ms
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:55:01 [notice] 42503#3460300: try again to bind() after 500ms
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 14:55:01 [emerg] 42503#3460300: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 14:55:01 [notice] 42503#3460300: try again to bind() after 500ms
2019/06/12 14:55:05 [notice] 42677#3460584: using the "kqueue" event method
2019/06/12 14:55:05 [notice] 42677#3460584: openresty/1.15.8.1
2019/06/12 14:55:05 [notice] 42677#3460584: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:55:05 [notice] 42677#3460584: OS: Darwin 18.6.0
2019/06/12 14:55:05 [notice] 42677#3460584: hw.ncpu: 8
2019/06/12 14:55:05 [notice] 42677#3460584: net.inet.tcp.sendspace: 131072
2019/06/12 14:55:05 [notice] 42677#3460584: kern.ipc.somaxconn: 128
2019/06/12 14:55:05 [notice] 42677#3460584: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:55:05 [notice] 42678#3460585: start worker processes
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42679
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42680
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42681
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42682
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42683
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42684
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42686
2019/06/12 14:55:05 [notice] 42678#3460585: start worker process 42687
2019/06/12 14:55:05 [notice] 42678#3460585: signal 23 (SIGIO) received
2019/06/12 14:55:05 [notice] 42678#3460585: signal 23 (SIGIO) received
2019/06/12 14:55:05 [notice] 42678#3460585: signal 23 (SIGIO) received from 42686
2019/06/12 14:55:11 [warn] 42686#3460593: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:55:11 [error] 42686#3460593: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:309):3: bad argument #1 to 'log' (expected table to have __tostring metamethod)
stack traceback:
coroutine 0:
	[C]: in function 'log'
	content_by_lua(nginx.conf:309):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:57:54 [notice] 43069#3466633: using the "kqueue" event method
2019/06/12 14:57:54 [notice] 43069#3466633: openresty/1.15.8.1
2019/06/12 14:57:54 [notice] 43069#3466633: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:57:54 [notice] 43069#3466633: OS: Darwin 18.6.0
2019/06/12 14:57:54 [notice] 43069#3466633: hw.ncpu: 8
2019/06/12 14:57:54 [notice] 43069#3466633: net.inet.tcp.sendspace: 131072
2019/06/12 14:57:54 [notice] 43069#3466633: kern.ipc.somaxconn: 128
2019/06/12 14:57:54 [notice] 43069#3466633: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:57:54 [notice] 43070#3466634: start worker processes
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43071
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43072
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43073
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43074
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43075
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43077
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43078
2019/06/12 14:57:54 [notice] 43070#3466634: start worker process 43079
2019/06/12 14:57:54 [notice] 43070#3466634: signal 23 (SIGIO) received
2019/06/12 14:57:54 [notice] 43070#3466634: signal 23 (SIGIO) received from 43078
2019/06/12 14:57:56 [warn] 43077#3466640: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:57:56 [info] 43077#3466640: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 14:58:40 [notice] 43344#3468362: using the "kqueue" event method
2019/06/12 14:58:40 [notice] 43344#3468362: openresty/1.15.8.1
2019/06/12 14:58:40 [notice] 43344#3468362: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 14:58:40 [notice] 43344#3468362: OS: Darwin 18.6.0
2019/06/12 14:58:40 [notice] 43344#3468362: hw.ncpu: 8
2019/06/12 14:58:40 [notice] 43344#3468362: net.inet.tcp.sendspace: 131072
2019/06/12 14:58:40 [notice] 43344#3468362: kern.ipc.somaxconn: 128
2019/06/12 14:58:40 [notice] 43344#3468362: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 14:58:40 [notice] 43345#3468364: start worker processes
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43346
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43347
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43348
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43349
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43350
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43352
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43353
2019/06/12 14:58:40 [notice] 43345#3468364: start worker process 43354
2019/06/12 14:58:40 [notice] 43345#3468364: signal 23 (SIGIO) received
2019/06/12 14:58:40 [notice] 43345#3468364: signal 23 (SIGIO) received from 43352
2019/06/12 14:58:40 [notice] 43345#3468364: signal 23 (SIGIO) received
2019/06/12 14:58:40 [notice] 43345#3468364: signal 23 (SIGIO) received from 43353
2019/06/12 14:58:42 [warn] 43350#3468371: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 14:58:42 [info] 43350#3468371: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:14:44 [notice] 44042#3499039: using the "kqueue" event method
2019/06/12 15:14:44 [notice] 44042#3499039: openresty/1.15.8.1
2019/06/12 15:14:44 [notice] 44042#3499039: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:14:44 [notice] 44042#3499039: OS: Darwin 18.6.0
2019/06/12 15:14:44 [notice] 44042#3499039: hw.ncpu: 8
2019/06/12 15:14:44 [notice] 44042#3499039: net.inet.tcp.sendspace: 131072
2019/06/12 15:14:44 [notice] 44042#3499039: kern.ipc.somaxconn: 128
2019/06/12 15:14:44 [notice] 44042#3499039: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:14:44 [notice] 44043#3499041: start worker processes
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44044
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44045
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44046
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44048
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44049
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44050
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44051
2019/06/12 15:14:44 [notice] 44043#3499041: start worker process 44052
2019/06/12 15:14:44 [notice] 44043#3499041: signal 23 (SIGIO) received
2019/06/12 15:14:44 [notice] 44043#3499041: signal 23 (SIGIO) received
2019/06/12 15:14:44 [notice] 44043#3499041: signal 23 (SIGIO) received from 44051
2019/06/12 15:14:46 [warn] 44048#3499045: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:312):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:46 [error] 44048#3499045: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):4: bad argument #1 to 'say' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'say'
	content_by_lua(nginx.conf:312):4: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:48 [warn] 44046#3499044: *2 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:312):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:48 [error] 44046#3499044: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):4: bad argument #1 to 'say' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'say'
	content_by_lua(nginx.conf:312):4: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:50 [warn] 44049#3499047: *3 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:312):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:50 [error] 44049#3499047: *3 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):4: bad argument #1 to 'say' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'say'
	content_by_lua(nginx.conf:312):4: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:54 [error] 44050#3499048: *4 "/Users/maliao/openresty-test/html/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:14:54 [info] 44050#3499048: *4 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:15:01 [error] 44046#3499044: *5 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):4: bad argument #1 to 'say' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'say'
	content_by_lua(nginx.conf:312):4: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:15:41 [notice] 44661#3502101: using the "kqueue" event method
2019/06/12 15:15:41 [notice] 44661#3502101: openresty/1.15.8.1
2019/06/12 15:15:41 [notice] 44661#3502101: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:15:41 [notice] 44661#3502101: OS: Darwin 18.6.0
2019/06/12 15:15:41 [notice] 44661#3502101: hw.ncpu: 8
2019/06/12 15:15:41 [notice] 44661#3502101: net.inet.tcp.sendspace: 131072
2019/06/12 15:15:41 [notice] 44661#3502101: kern.ipc.somaxconn: 128
2019/06/12 15:15:41 [notice] 44661#3502101: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:15:41 [notice] 44662#3502102: start worker processes
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44663
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44664
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44665
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44667
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44668
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44669
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44670
2019/06/12 15:15:41 [notice] 44662#3502102: start worker process 44671
2019/06/12 15:15:41 [notice] 44662#3502102: signal 23 (SIGIO) received from 44668
2019/06/12 15:15:41 [notice] 44662#3502102: signal 23 (SIGIO) received from 44669
2019/06/12 15:15:41 [notice] 44662#3502102: signal 23 (SIGIO) received from 44670
2019/06/12 15:15:42 [warn] 44670#3502110: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:312):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:15:42 [notice] 44670#3502110: *1 [lua] content_by_lua(nginx.conf:312):3: 200, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:15:42 [error] 44670#3502110: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):4: bad argument #1 to 'print' (expected table to have __tostring metamethod)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:312):4: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:16:44 [notice] 44937#3504064: using the "kqueue" event method
2019/06/12 15:16:44 [notice] 44937#3504064: openresty/1.15.8.1
2019/06/12 15:16:44 [notice] 44937#3504064: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:16:44 [notice] 44937#3504064: OS: Darwin 18.6.0
2019/06/12 15:16:44 [notice] 44937#3504064: hw.ncpu: 8
2019/06/12 15:16:44 [notice] 44937#3504064: net.inet.tcp.sendspace: 131072
2019/06/12 15:16:44 [notice] 44937#3504064: kern.ipc.somaxconn: 128
2019/06/12 15:16:44 [notice] 44937#3504064: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:16:44 [notice] 44938#3504068: start worker processes
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44939
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44940
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44941
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44942
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44943
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44945
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44946
2019/06/12 15:16:44 [notice] 44938#3504068: start worker process 44947
2019/06/12 15:16:44 [notice] 44938#3504068: signal 23 (SIGIO) received
2019/06/12 15:16:44 [notice] 44938#3504068: signal 23 (SIGIO) received
2019/06/12 15:16:44 [notice] 44938#3504068: signal 23 (SIGIO) received from 44946
2019/06/12 15:16:46 [warn] 44946#3504076: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:16:46 [error] 44946#3504076: *1 [lua] content_by_lua(nginx.conf:309):3: res, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:16:46 [info] 44946#3504076: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:17:09 [notice] 45208#3505091: using the "kqueue" event method
2019/06/12 15:17:09 [notice] 45208#3505091: openresty/1.15.8.1
2019/06/12 15:17:09 [notice] 45208#3505091: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:17:09 [notice] 45208#3505091: OS: Darwin 18.6.0
2019/06/12 15:17:09 [notice] 45208#3505091: hw.ncpu: 8
2019/06/12 15:17:09 [notice] 45208#3505091: net.inet.tcp.sendspace: 131072
2019/06/12 15:17:09 [notice] 45208#3505091: kern.ipc.somaxconn: 128
2019/06/12 15:17:09 [notice] 45208#3505091: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:17:09 [notice] 45209#3505096: start worker processes
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45210
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45211
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45212
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45213
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45214
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45216
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45217
2019/06/12 15:17:09 [notice] 45209#3505096: start worker process 45218
2019/06/12 15:17:09 [notice] 45209#3505096: signal 23 (SIGIO) received
2019/06/12 15:17:09 [notice] 45209#3505096: signal 23 (SIGIO) received
2019/06/12 15:17:11 [notice] 45390#3505389: using the "kqueue" event method
2019/06/12 15:17:11 [notice] 45390#3505389: openresty/1.15.8.1
2019/06/12 15:17:11 [notice] 45390#3505389: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:17:11 [notice] 45390#3505389: OS: Darwin 18.6.0
2019/06/12 15:17:11 [notice] 45390#3505389: hw.ncpu: 8
2019/06/12 15:17:11 [notice] 45390#3505389: net.inet.tcp.sendspace: 131072
2019/06/12 15:17:11 [notice] 45390#3505389: kern.ipc.somaxconn: 128
2019/06/12 15:17:11 [notice] 45390#3505389: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:17:11 [notice] 45391#3505390: start worker processes
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45392
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45393
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45394
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45395
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45396
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45398
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45399
2019/06/12 15:17:11 [notice] 45391#3505390: start worker process 45400
2019/06/12 15:17:11 [notice] 45391#3505390: signal 23 (SIGIO) received
2019/06/12 15:17:11 [notice] 45391#3505390: signal 23 (SIGIO) received from 45399
2019/06/12 15:17:13 [warn] 45400#3505399: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:17:13 [error] 45400#3505399: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:309):3: bad argument #1 to 'log' (expected table to have __tostring metamethod)
stack traceback:
coroutine 0:
	[C]: in function 'log'
	content_by_lua(nginx.conf:309):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:19:12 [warn] 45395#3505394: *2 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:19:12 [error] 45395#3505394: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:309):3: bad argument #1 to 'log' (expected table to have __tostring metamethod)
stack traceback:
coroutine 0:
	[C]: in function 'log'
	content_by_lua(nginx.conf:309):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:19:18 [notice] 45844#3508741: using the "kqueue" event method
2019/06/12 15:19:18 [notice] 45844#3508741: openresty/1.15.8.1
2019/06/12 15:19:18 [notice] 45844#3508741: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:19:18 [notice] 45844#3508741: OS: Darwin 18.6.0
2019/06/12 15:19:18 [notice] 45844#3508741: hw.ncpu: 8
2019/06/12 15:19:18 [notice] 45844#3508741: net.inet.tcp.sendspace: 131072
2019/06/12 15:19:18 [notice] 45844#3508741: kern.ipc.somaxconn: 128
2019/06/12 15:19:18 [notice] 45844#3508741: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:19:18 [notice] 45845#3508746: start worker processes
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45846
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45847
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45848
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45849
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45850
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45852
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45853
2019/06/12 15:19:18 [notice] 45845#3508746: start worker process 45854
2019/06/12 15:19:18 [notice] 45845#3508746: signal 23 (SIGIO) received
2019/06/12 15:19:18 [notice] 45845#3508746: signal 23 (SIGIO) received from 45853
2019/06/12 15:19:19 [warn] 45846#3508747: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:19:19 [info] 45846#3508747: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:21:47 [notice] 46130#3515541: using the "kqueue" event method
2019/06/12 15:21:47 [notice] 46130#3515541: openresty/1.15.8.1
2019/06/12 15:21:47 [notice] 46130#3515541: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:21:47 [notice] 46130#3515541: OS: Darwin 18.6.0
2019/06/12 15:21:47 [notice] 46130#3515541: hw.ncpu: 8
2019/06/12 15:21:47 [notice] 46130#3515541: net.inet.tcp.sendspace: 131072
2019/06/12 15:21:47 [notice] 46130#3515541: kern.ipc.somaxconn: 128
2019/06/12 15:21:47 [notice] 46130#3515541: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:21:47 [notice] 46131#3515546: start worker processes
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46132
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46133
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46134
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46135
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46136
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46138
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46139
2019/06/12 15:21:47 [notice] 46131#3515546: start worker process 46140
2019/06/12 15:21:47 [notice] 46131#3515546: signal 23 (SIGIO) received
2019/06/12 15:21:47 [notice] 46131#3515546: signal 23 (SIGIO) received from 46139
2019/06/12 15:21:49 [warn] 46139#3515554: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:312):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:21:49 [error] 46139#3515554: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):3: bad argument #1 to 'print' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:312):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:22:07 [error] 46139#3515554: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:312):3: bad argument #1 to 'print' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:312):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:22:11 [notice] 46487#3516645: using the "kqueue" event method
2019/06/12 15:22:11 [notice] 46487#3516645: openresty/1.15.8.1
2019/06/12 15:22:11 [notice] 46487#3516645: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:22:11 [notice] 46487#3516645: OS: Darwin 18.6.0
2019/06/12 15:22:11 [notice] 46487#3516645: hw.ncpu: 8
2019/06/12 15:22:11 [notice] 46487#3516645: net.inet.tcp.sendspace: 131072
2019/06/12 15:22:11 [notice] 46487#3516645: kern.ipc.somaxconn: 128
2019/06/12 15:22:11 [notice] 46487#3516645: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:22:11 [notice] 46488#3516648: start worker processes
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46489
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46490
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46491
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46492
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46494
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46495
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46496
2019/06/12 15:22:11 [notice] 46488#3516648: start worker process 46497
2019/06/12 15:22:11 [notice] 46488#3516648: signal 23 (SIGIO) received
2019/06/12 15:22:11 [notice] 46488#3516648: signal 23 (SIGIO) received from 46495
2019/06/12 15:22:11 [notice] 46488#3516648: signal 23 (SIGIO) received from 46496
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 15:22:17 [notice] 46583#3516916: try again to bind() after 500ms
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 15:22:17 [notice] 46583#3516916: try again to bind() after 500ms
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 15:22:17 [emerg] 46583#3516916: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 15:22:17 [notice] 46583#3516916: try again to bind() after 500ms
2019/06/12 15:22:20 [notice] 46757#3517249: using the "kqueue" event method
2019/06/12 15:22:20 [notice] 46757#3517249: openresty/1.15.8.1
2019/06/12 15:22:20 [notice] 46757#3517249: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:22:20 [notice] 46757#3517249: OS: Darwin 18.6.0
2019/06/12 15:22:20 [notice] 46757#3517249: hw.ncpu: 8
2019/06/12 15:22:20 [notice] 46757#3517249: net.inet.tcp.sendspace: 131072
2019/06/12 15:22:20 [notice] 46757#3517249: kern.ipc.somaxconn: 128
2019/06/12 15:22:20 [notice] 46757#3517249: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:22:20 [notice] 46758#3517250: start worker processes
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46759
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46760
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46761
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46762
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46763
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46765
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46766
2019/06/12 15:22:20 [notice] 46758#3517250: start worker process 46767
2019/06/12 15:22:20 [notice] 46758#3517250: signal 23 (SIGIO) received from 46765
2019/06/12 15:22:20 [notice] 46758#3517250: signal 23 (SIGIO) received
2019/06/12 15:22:20 [notice] 46758#3517250: signal 23 (SIGIO) received from 46766
2019/06/12 15:22:23 [warn] 46766#3517258: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:311):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:22:23 [error] 46766#3517258: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:311):3: bad argument #1 to 'print' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:311):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:22:37 [notice] 47028#3518141: using the "kqueue" event method
2019/06/12 15:22:37 [notice] 47028#3518141: openresty/1.15.8.1
2019/06/12 15:22:37 [notice] 47028#3518141: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:22:37 [notice] 47028#3518141: OS: Darwin 18.6.0
2019/06/12 15:22:37 [notice] 47028#3518141: hw.ncpu: 8
2019/06/12 15:22:37 [notice] 47028#3518141: net.inet.tcp.sendspace: 131072
2019/06/12 15:22:37 [notice] 47028#3518141: kern.ipc.somaxconn: 128
2019/06/12 15:22:37 [notice] 47028#3518141: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:22:37 [notice] 47029#3518143: start worker processes
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47030
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47031
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47032
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47034
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47035
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47036
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47037
2019/06/12 15:22:37 [notice] 47029#3518143: start worker process 47038
2019/06/12 15:22:37 [notice] 47029#3518143: signal 23 (SIGIO) received
2019/06/12 15:22:37 [notice] 47029#3518143: signal 23 (SIGIO) received from 47037
2019/06/12 15:22:38 [warn] 47037#3518151: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:311):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:22:38 [error] 47037#3518151: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:311):3: bad argument #1 to 'print' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:311):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:23:14 [notice] 47387#3519326: using the "kqueue" event method
2019/06/12 15:23:14 [notice] 47387#3519326: openresty/1.15.8.1
2019/06/12 15:23:14 [notice] 47387#3519326: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:23:14 [notice] 47387#3519326: OS: Darwin 18.6.0
2019/06/12 15:23:14 [notice] 47387#3519326: hw.ncpu: 8
2019/06/12 15:23:14 [notice] 47387#3519326: net.inet.tcp.sendspace: 131072
2019/06/12 15:23:14 [notice] 47387#3519326: kern.ipc.somaxconn: 128
2019/06/12 15:23:14 [notice] 47387#3519326: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:23:14 [notice] 47388#3519329: start worker processes
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47389
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47390
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47391
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47392
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47394
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47395
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47396
2019/06/12 15:23:14 [notice] 47388#3519329: start worker process 47397
2019/06/12 15:23:14 [notice] 47388#3519329: signal 23 (SIGIO) received
2019/06/12 15:23:14 [notice] 47388#3519329: signal 23 (SIGIO) received from 47395
2019/06/12 15:23:14 [notice] 47388#3519329: signal 23 (SIGIO) received from 47396
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 15:23:20 [notice] 47484#3519571: try again to bind() after 500ms
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 15:23:20 [notice] 47484#3519571: try again to bind() after 500ms
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:6699 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:80 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:81 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:82 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:83 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:84 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:85 failed (48: Address already in use)
2019/06/12 15:23:20 [emerg] 47484#3519571: bind() to 0.0.0.0:8899 failed (48: Address already in use)
2019/06/12 15:23:20 [notice] 47484#3519571: try again to bind() after 500ms
2019/06/12 15:23:24 [notice] 47657#3519896: using the "kqueue" event method
2019/06/12 15:23:24 [notice] 47657#3519896: openresty/1.15.8.1
2019/06/12 15:23:24 [notice] 47657#3519896: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:23:24 [notice] 47657#3519896: OS: Darwin 18.6.0
2019/06/12 15:23:24 [notice] 47657#3519896: hw.ncpu: 8
2019/06/12 15:23:24 [notice] 47657#3519896: net.inet.tcp.sendspace: 131072
2019/06/12 15:23:24 [notice] 47657#3519896: kern.ipc.somaxconn: 128
2019/06/12 15:23:24 [notice] 47657#3519896: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:23:24 [notice] 47658#3519897: start worker processes
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47659
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47660
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47661
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47662
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47664
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47665
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47666
2019/06/12 15:23:24 [notice] 47658#3519897: start worker process 47667
2019/06/12 15:23:24 [notice] 47658#3519897: signal 23 (SIGIO) received
2019/06/12 15:23:24 [notice] 47658#3519897: signal 23 (SIGIO) received from 47665
2019/06/12 15:23:24 [notice] 47658#3519897: signal 23 (SIGIO) received from 47666
2019/06/12 15:23:30 [warn] 47665#3519904: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:310):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:23:30 [error] 47665#3519904: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:310):3: bad argument #1 to 'print' (non-array table found)
stack traceback:
coroutine 0:
	[C]: in function 'print'
	content_by_lua(nginx.conf:310):3: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:23:53 [notice] 48186#3521335: using the "kqueue" event method
2019/06/12 15:23:53 [notice] 48186#3521335: openresty/1.15.8.1
2019/06/12 15:23:53 [notice] 48186#3521335: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:23:53 [notice] 48186#3521335: OS: Darwin 18.6.0
2019/06/12 15:23:53 [notice] 48186#3521335: hw.ncpu: 8
2019/06/12 15:23:53 [notice] 48186#3521335: net.inet.tcp.sendspace: 131072
2019/06/12 15:23:53 [notice] 48186#3521335: kern.ipc.somaxconn: 128
2019/06/12 15:23:53 [notice] 48186#3521335: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:23:53 [notice] 48187#3521337: start worker processes
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48188
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48189
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48190
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48191
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48193
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48194
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48195
2019/06/12 15:23:53 [notice] 48187#3521337: start worker process 48196
2019/06/12 15:23:53 [notice] 48187#3521337: signal 23 (SIGIO) received from 48191
2019/06/12 15:23:53 [notice] 48187#3521337: signal 23 (SIGIO) received
2019/06/12 15:23:53 [notice] 48187#3521337: signal 23 (SIGIO) received from 48194
2019/06/12 15:23:53 [notice] 48187#3521337: signal 23 (SIGIO) received
2019/06/12 15:23:53 [notice] 48187#3521337: signal 23 (SIGIO) received from 48195
2019/06/12 15:23:57 [warn] 48196#3521346: *1 [lua] _G write guard:12: __newindex(): writing a global lua variable ('res') which may lead to race conditions between concurrent requests, so prefer the use of 'local' variables
stack traceback:
	content_by_lua(nginx.conf:309):2: in main chunk, client: 127.0.0.1, server: , request: "GET /foo HTTP/1.1", host: "127.0.0.1:85"
2019/06/12 15:23:57 [info] 48196#3521346: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:56:50 [notice] 49070#3579819: using the "kqueue" event method
2019/06/12 15:56:50 [notice] 49070#3579819: openresty/1.15.8.1
2019/06/12 15:56:50 [notice] 49070#3579819: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:56:50 [notice] 49070#3579819: OS: Darwin 18.6.0
2019/06/12 15:56:50 [notice] 49070#3579819: hw.ncpu: 8
2019/06/12 15:56:50 [notice] 49070#3579819: net.inet.tcp.sendspace: 131072
2019/06/12 15:56:50 [notice] 49070#3579819: kern.ipc.somaxconn: 128
2019/06/12 15:56:50 [notice] 49070#3579819: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:56:50 [notice] 49072#3579874: start worker processes
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49073
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49074
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49075
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49076
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49077
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49078
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49080
2019/06/12 15:56:50 [notice] 49072#3579874: start worker process 49081
2019/06/12 15:56:53 [notice] 49072#3579874: signal 23 (SIGIO) received
2019/06/12 15:56:53 [notice] 49072#3579874: signal 23 (SIGIO) received
2019/06/12 15:56:53 [notice] 49072#3579874: signal 23 (SIGIO) received from 49080
2019/06/12 15:57:10 [notice] 49424#3580769: using the "kqueue" event method
2019/06/12 15:57:10 [notice] 49424#3580769: openresty/1.15.8.1
2019/06/12 15:57:10 [notice] 49424#3580769: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 15:57:10 [notice] 49424#3580769: OS: Darwin 18.6.0
2019/06/12 15:57:10 [notice] 49424#3580769: hw.ncpu: 8
2019/06/12 15:57:10 [notice] 49424#3580769: net.inet.tcp.sendspace: 131072
2019/06/12 15:57:10 [notice] 49424#3580769: kern.ipc.somaxconn: 128
2019/06/12 15:57:10 [notice] 49424#3580769: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 15:57:10 [notice] 49425#3580770: start worker processes
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49426
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49427
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49428
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49429
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49430
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49432
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49434
2019/06/12 15:57:10 [notice] 49425#3580770: start worker process 49435
2019/06/12 15:57:10 [notice] 49425#3580770: signal 23 (SIGIO) received
2019/06/12 15:57:10 [notice] 49425#3580770: signal 23 (SIGIO) received
2019/06/12 15:57:10 [notice] 49425#3580770: signal 23 (SIGIO) received
2019/06/12 15:57:10 [notice] 49425#3580770: signal 23 (SIGIO) received
2019/06/12 15:57:10 [notice] 49425#3580770: signal 23 (SIGIO) received
2019/06/12 15:57:10 [notice] 49425#3580770: signal 23 (SIGIO) received from 49434
2019/06/12 15:58:07 [info] 49435#3580780: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:58:09 [info] 49434#3580779: *2 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 15:59:09 [info] 49435#3580780: *3 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:13:15 [notice] 53889#3787675: using the "kqueue" event method
2019/06/12 17:13:15 [notice] 53889#3787675: openresty/1.15.8.1
2019/06/12 17:13:15 [notice] 53889#3787675: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:13:15 [notice] 53889#3787675: OS: Darwin 18.6.0
2019/06/12 17:13:15 [notice] 53889#3787675: hw.ncpu: 8
2019/06/12 17:13:15 [notice] 53889#3787675: net.inet.tcp.sendspace: 131072
2019/06/12 17:13:15 [notice] 53889#3787675: kern.ipc.somaxconn: 128
2019/06/12 17:13:15 [notice] 53889#3787675: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:13:15 [notice] 53890#3787677: start worker processes
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53891
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53892
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53893
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53895
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53896
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53898
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53900
2019/06/12 17:13:15 [notice] 53890#3787677: start worker process 53901
2019/06/12 17:13:15 [notice] 53890#3787677: signal 23 (SIGIO) received
2019/06/12 17:13:15 [notice] 53890#3787677: signal 23 (SIGIO) received
2019/06/12 17:13:22 [notice] 54074#3788166: using the "kqueue" event method
2019/06/12 17:13:22 [notice] 54074#3788166: openresty/1.15.8.1
2019/06/12 17:13:22 [notice] 54074#3788166: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:13:22 [notice] 54074#3788166: OS: Darwin 18.6.0
2019/06/12 17:13:22 [notice] 54074#3788166: hw.ncpu: 8
2019/06/12 17:13:22 [notice] 54074#3788166: net.inet.tcp.sendspace: 131072
2019/06/12 17:13:22 [notice] 54074#3788166: kern.ipc.somaxconn: 128
2019/06/12 17:13:22 [notice] 54074#3788166: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:13:22 [notice] 54075#3788167: start worker processes
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54076
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54077
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54078
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54079
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54081
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54082
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54083
2019/06/12 17:13:22 [notice] 54075#3788167: start worker process 54084
2019/06/12 17:13:22 [notice] 54075#3788167: signal 23 (SIGIO) received
2019/06/12 17:13:22 [notice] 54075#3788167: signal 23 (SIGIO) received from 54082
2019/06/12 17:13:22 [notice] 54075#3788167: signal 23 (SIGIO) received
2019/06/12 17:13:22 [notice] 54075#3788167: signal 23 (SIGIO) received from 54083
2019/06/12 17:14:08 [error] 54082#3788174: *1 "/Users/maliao/openresty-test/html/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:14:08 [info] 54082#3788174: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:14:18 [error] 54084#3788176: *2 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:15:01 [error] 54082#3788174: *3 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:15:06 [error] 54077#3788169: *4 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:15:40 [error] 54078#3788170: *5 open() "/Users/maliao/openresty-test/html/test" failed (2: No such file or directory), client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:91"
2019/06/12 17:15:40 [info] 54078#3788170: *5 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:16:07 [error] 54084#3788176: *8 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:412):4: attempt to concatenate local 'data' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:412): in main chunk, client: 127.0.0.1, server: , request: "GET /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:16:07 [info] 54081#3788173: *6 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:17:45 [error] 54083#3788175: *11 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:412):4: attempt to concatenate local 'data' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:412): in main chunk, client: 127.0.0.1, server: , request: "GET /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:17:45 [info] 54079#3788171: *9 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:17:52 [error] 54081#3788173: *12 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:19:10 [error] 54077#3788169: *13 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:19:11 [error] 54084#3788176: *16 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:412):4: attempt to concatenate local 'data' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:412): in main chunk, client: 127.0.0.1, server: , request: "GET /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:19:11 [info] 54083#3788175: *14 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:19:12 [error] 54084#3788176: *17 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:21:07 [error] 54083#3788175: *18 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:21:11 [error] 54084#3788176: *19 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:21:17 [error] 54081#3788173: *20 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:22:49 [error] 54084#3788176: *21 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:23:43 [error] 54079#3788171: *22 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:23:59 [error] 54082#3788174: *23 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:24:59 [notice] 55888#3805149: using the "kqueue" event method
2019/06/12 17:24:59 [notice] 55888#3805149: openresty/1.15.8.1
2019/06/12 17:24:59 [notice] 55888#3805149: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:24:59 [notice] 55888#3805149: OS: Darwin 18.6.0
2019/06/12 17:24:59 [notice] 55888#3805149: hw.ncpu: 8
2019/06/12 17:24:59 [notice] 55888#3805149: net.inet.tcp.sendspace: 131072
2019/06/12 17:24:59 [notice] 55888#3805149: kern.ipc.somaxconn: 128
2019/06/12 17:24:59 [notice] 55888#3805149: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:24:59 [notice] 55889#3805150: start worker processes
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55890
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55891
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55892
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55893
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55895
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55896
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55897
2019/06/12 17:24:59 [notice] 55889#3805150: start worker process 55898
2019/06/12 17:24:59 [notice] 55889#3805150: signal 23 (SIGIO) received
2019/06/12 17:24:59 [notice] 55889#3805150: signal 23 (SIGIO) received from 55897
2019/06/12 17:25:13 [error] 55892#3805153: *1 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "POST /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:25:38 [error] 55892#3805153: *2 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:25:48 [error] 55896#3805157: *3 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test?a=1 HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:26:00 [error] 55893#3805154: *4 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test?a=1&key=ads HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:26:04 [error] 55895#3805156: *5 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test?a=asd&key=ads HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:26:07 [error] 55891#3805152: *6 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test?&key=ads HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:26:10 [error] 55891#3805152: *7 failed to load inlined Lua code: content_by_lua(nginx.conf:392):5: unexpected symbol near '#', client: 127.0.0.1, server: , request: "GET /test?key=ads HTTP/1.1", host: "127.0.0.1:90"
2019/06/12 17:27:09 [notice] 56690#3809326: using the "kqueue" event method
2019/06/12 17:27:09 [notice] 56690#3809326: openresty/1.15.8.1
2019/06/12 17:27:09 [notice] 56690#3809326: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:27:09 [notice] 56690#3809326: OS: Darwin 18.6.0
2019/06/12 17:27:09 [notice] 56690#3809326: hw.ncpu: 8
2019/06/12 17:27:09 [notice] 56690#3809326: net.inet.tcp.sendspace: 131072
2019/06/12 17:27:09 [notice] 56690#3809326: kern.ipc.somaxconn: 128
2019/06/12 17:27:09 [notice] 56690#3809326: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:27:09 [notice] 56691#3809327: start worker processes
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56692
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56693
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56694
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56695
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56697
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56699
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56700
2019/06/12 17:27:09 [notice] 56691#3809327: start worker process 56701
2019/06/12 17:27:10 [notice] 56691#3809327: signal 23 (SIGIO) received
2019/06/12 17:27:10 [notice] 56691#3809327: signal 23 (SIGIO) received
2019/06/12 17:27:10 [notice] 56691#3809327: signal 23 (SIGIO) received from 56700
2019/06/12 17:28:07 [error] 56701#3809337: *3 failed to load inlined Lua code: content_by_lua(nginx.conf:411):4: unexpected symbol near ')', client: 127.0.0.1, server: , request: "POST /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:29:01 [notice] 57073#3813388: using the "kqueue" event method
2019/06/12 17:29:01 [notice] 57073#3813388: openresty/1.15.8.1
2019/06/12 17:29:01 [notice] 57073#3813388: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:29:01 [notice] 57073#3813388: OS: Darwin 18.6.0
2019/06/12 17:29:01 [notice] 57073#3813388: hw.ncpu: 8
2019/06/12 17:29:01 [notice] 57073#3813388: net.inet.tcp.sendspace: 131072
2019/06/12 17:29:01 [notice] 57073#3813388: kern.ipc.somaxconn: 128
2019/06/12 17:29:01 [notice] 57073#3813388: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:29:01 [notice] 57074#3813389: start worker processes
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57075
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57076
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57078
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57079
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57080
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57082
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57083
2019/06/12 17:29:01 [notice] 57074#3813389: start worker process 57084
2019/06/12 17:29:01 [notice] 57074#3813389: signal 23 (SIGIO) received
2019/06/12 17:29:02 [info] 57084#3813400: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:29:04 [info] 57078#3813393: *4 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:29:08 [info] 57084#3813400: *7 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:29:18 [info] 57083#3813399: *8 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:29:25 [info] 57079#3813394: *11 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:04 [info] 57080#3813395: *6 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:07 [info] 57080#3813395: *14 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:08 [info] 57083#3813399: *3 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:14 [notice] 57780#3815684: using the "kqueue" event method
2019/06/12 17:30:14 [notice] 57780#3815684: openresty/1.15.8.1
2019/06/12 17:30:14 [notice] 57780#3815684: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:30:14 [notice] 57780#3815684: OS: Darwin 18.6.0
2019/06/12 17:30:14 [notice] 57780#3815684: hw.ncpu: 8
2019/06/12 17:30:14 [notice] 57780#3815684: net.inet.tcp.sendspace: 131072
2019/06/12 17:30:14 [notice] 57780#3815684: kern.ipc.somaxconn: 128
2019/06/12 17:30:14 [notice] 57780#3815684: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:30:14 [notice] 57781#3815685: start worker processes
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57782
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57783
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57784
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57786
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57787
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57788
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57790
2019/06/12 17:30:14 [notice] 57781#3815685: start worker process 57791
2019/06/12 17:30:14 [notice] 57781#3815685: signal 23 (SIGIO) received
2019/06/12 17:30:14 [notice] 57781#3815685: signal 23 (SIGIO) received from 57790
2019/06/12 17:30:15 [error] 57790#3815694: *3 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:412):4: attempt to concatenate local 'data' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:412): in main chunk, client: 127.0.0.1, server: , request: "POST /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:30:18 [info] 57788#3815692: *4 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:21 [info] 57788#3815692: *7 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:29 [info] 57788#3815692: *8 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:31 [info] 57787#3815691: *9 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:37 [info] 57783#3815687: *12 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:30:46 [info] 57784#3815688: *15 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:31:29 [info] 57791#3815695: *6 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:31:31 [info] 57791#3815695: *11 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:31:37 [info] 57791#3815695: *14 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:31:46 [info] 57786#3815690: *17 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:31:53 [error] 57790#3815694: *20 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:412):4: attempt to concatenate local 'data' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:412): in main chunk, client: 127.0.0.1, server: , request: "POST /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:31:57 [info] 57787#3815691: *21 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:32:01 [info] 57788#3815692: *24 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:32:05 [info] 57784#3815688: *27 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:32:57 [info] 57786#3815690: *23 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:33:01 [info] 57790#3815694: *26 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:33:05 [info] 57788#3815692: *29 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:43:55 [notice] 62006#3849102: using the "kqueue" event method
2019/06/12 17:43:55 [notice] 62006#3849102: openresty/1.15.8.1
2019/06/12 17:43:55 [notice] 62006#3849102: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/12 17:43:55 [notice] 62006#3849102: OS: Darwin 18.6.0
2019/06/12 17:43:55 [notice] 62006#3849102: hw.ncpu: 8
2019/06/12 17:43:55 [notice] 62006#3849102: net.inet.tcp.sendspace: 131072
2019/06/12 17:43:55 [notice] 62006#3849102: kern.ipc.somaxconn: 128
2019/06/12 17:43:55 [notice] 62006#3849102: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/12 17:43:55 [notice] 62008#3849105: start worker processes
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62009
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62010
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62011
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62012
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62013
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62014
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62015
2019/06/12 17:43:55 [notice] 62008#3849105: start worker process 62016
2019/06/12 17:43:56 [notice] 62008#3849105: signal 23 (SIGIO) received
2019/06/12 17:43:56 [notice] 62008#3849105: signal 23 (SIGIO) received from 62014
2019/06/12 17:43:56 [notice] 62008#3849105: signal 23 (SIGIO) received from 62015
2019/06/12 17:44:19 [info] 62014#3849111: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:44:36 [info] 62013#3849110: *4 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:45:19 [info] 62016#3849113: *3 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:45:36 [info] 62016#3849113: *6 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:50:04 [info] 62016#3849113: *8 client timed out (60: Operation timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:6699
2019/06/12 17:57:41 [info] 62015#3849112: *9 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:57:51 [info] 62016#3849113: *12 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/12 17:57:57 [error] 62016#3849113: *11 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:412):4: attempt to concatenate local 'data' (a nil value)
stack traceback:
coroutine 0:
	content_by_lua(nginx.conf:412): in main chunk, client: 127.0.0.1, server: , request: "POST /spe_md5 HTTP/1.1", host: "md5_server"
2019/06/12 17:58:51 [info] 62012#3849109: *14 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 09:48:40 [notice] 67911#4170915: using the "kqueue" event method
2019/06/13 09:48:40 [notice] 67911#4170915: openresty/1.15.8.1
2019/06/13 09:48:40 [notice] 67911#4170915: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 09:48:40 [notice] 67911#4170915: OS: Darwin 18.6.0
2019/06/13 09:48:40 [notice] 67911#4170915: hw.ncpu: 8
2019/06/13 09:48:40 [notice] 67911#4170915: net.inet.tcp.sendspace: 131072
2019/06/13 09:48:40 [notice] 67911#4170915: kern.ipc.somaxconn: 128
2019/06/13 09:48:40 [notice] 67911#4170915: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 09:48:40 [notice] 67912#4170916: start worker processes
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67913
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67914
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67915
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67916
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67917
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67918
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67919
2019/06/13 09:48:40 [notice] 67912#4170916: start worker process 67920
2019/06/13 09:48:40 [notice] 67912#4170916: signal 23 (SIGIO) received
2019/06/13 09:48:40 [notice] 67912#4170916: signal 23 (SIGIO) received from 67918
2019/06/13 09:48:40 [notice] 67912#4170916: signal 23 (SIGIO) received from 67919
2019/06/13 09:49:27 [info] 67920#4170924: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 09:49:59 [notice] 68097#4172223: using the "kqueue" event method
2019/06/13 09:49:59 [notice] 68097#4172223: openresty/1.15.8.1
2019/06/13 09:49:59 [notice] 68097#4172223: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 09:49:59 [notice] 68097#4172223: OS: Darwin 18.6.0
2019/06/13 09:49:59 [notice] 68097#4172223: hw.ncpu: 8
2019/06/13 09:49:59 [notice] 68097#4172223: net.inet.tcp.sendspace: 131072
2019/06/13 09:49:59 [notice] 68097#4172223: kern.ipc.somaxconn: 128
2019/06/13 09:49:59 [notice] 68097#4172223: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 09:49:59 [notice] 68098#4172227: start worker processes
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68099
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68100
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68101
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68102
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68103
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68104
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68106
2019/06/13 09:49:59 [notice] 68098#4172227: start worker process 68107
2019/06/13 09:49:59 [notice] 68098#4172227: signal 23 (SIGIO) received
2019/06/13 09:49:59 [notice] 68098#4172227: signal 23 (SIGIO) received from 68104
2019/06/13 09:49:59 [notice] 68098#4172227: signal 23 (SIGIO) received from 68106
2019/06/13 09:50:00 [info] 68107#4172236: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 09:50:02 [info] 68107#4172236: *3 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 09:56:14 [notice] 68564#4181067: using the "kqueue" event method
2019/06/13 09:56:14 [notice] 68564#4181067: openresty/1.15.8.1
2019/06/13 09:56:14 [notice] 68564#4181067: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 09:56:14 [notice] 68564#4181067: OS: Darwin 18.6.0
2019/06/13 09:56:14 [notice] 68564#4181067: hw.ncpu: 8
2019/06/13 09:56:14 [notice] 68564#4181067: net.inet.tcp.sendspace: 131072
2019/06/13 09:56:14 [notice] 68564#4181067: kern.ipc.somaxconn: 128
2019/06/13 09:56:14 [notice] 68564#4181067: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 09:56:14 [notice] 68565#4181071: start worker processes
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68566
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68567
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68568
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68569
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68570
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68571
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68572
2019/06/13 09:56:14 [notice] 68565#4181071: start worker process 68573
2019/06/13 09:56:14 [notice] 68565#4181071: signal 23 (SIGIO) received
2019/06/13 09:56:14 [notice] 68565#4181071: signal 23 (SIGIO) received from 68572
2019/06/13 09:56:19 [info] 68567#4181073: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 10:49:44 [notice] 71143#4268168: using the "kqueue" event method
2019/06/13 10:49:44 [notice] 71143#4268168: openresty/1.15.8.1
2019/06/13 10:49:44 [notice] 71143#4268168: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 10:49:44 [notice] 71143#4268168: OS: Darwin 18.6.0
2019/06/13 10:49:44 [notice] 71143#4268168: hw.ncpu: 8
2019/06/13 10:49:44 [notice] 71143#4268168: net.inet.tcp.sendspace: 131072
2019/06/13 10:49:44 [notice] 71143#4268168: kern.ipc.somaxconn: 128
2019/06/13 10:49:44 [notice] 71143#4268168: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 10:49:44 [notice] 71144#4268170: start worker processes
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71145
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71146
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71147
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71148
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71149
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71150
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71151
2019/06/13 10:49:44 [notice] 71144#4268170: start worker process 71152
2019/06/13 10:49:44 [notice] 71144#4268170: signal 23 (SIGIO) received
2019/06/13 10:49:44 [notice] 71144#4268170: signal 23 (SIGIO) received from 71150
2019/06/13 10:49:44 [notice] 71144#4268170: signal 23 (SIGIO) received from 71151
2019/06/13 10:49:47 [info] 71152#4268178: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 10:49:50 [error] 71151#4268177: *3 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:517):2: module 'resty.redis_iresty' not found:
	no field package.preload['resty.redis_iresty']
	no file '/Users/maliao/openresty-test//lua/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.lua'
	no file './resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.so'
	no file './resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
coroutine 0:
	[C]: in function 'require'
	content_by_lua(nginx.conf:517):2: in main chunk, client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:51:35 [notice] 71418#4269894: using the "kqueue" event method
2019/06/13 10:51:35 [notice] 71418#4269894: openresty/1.15.8.1
2019/06/13 10:51:35 [notice] 71418#4269894: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 10:51:35 [notice] 71418#4269894: OS: Darwin 18.6.0
2019/06/13 10:51:35 [notice] 71418#4269894: hw.ncpu: 8
2019/06/13 10:51:35 [notice] 71418#4269894: net.inet.tcp.sendspace: 131072
2019/06/13 10:51:35 [notice] 71418#4269894: kern.ipc.somaxconn: 128
2019/06/13 10:51:35 [notice] 71418#4269894: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 10:51:35 [notice] 71419#4269912: start worker processes
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71420
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71421
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71422
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71423
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71425
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71426
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71427
2019/06/13 10:51:35 [notice] 71419#4269912: start worker process 71428
2019/06/13 10:51:35 [notice] 71419#4269912: signal 23 (SIGIO) received
2019/06/13 10:51:35 [notice] 71419#4269912: signal 23 (SIGIO) received
2019/06/13 10:51:35 [notice] 71419#4269912: signal 23 (SIGIO) received from 71425
2019/06/13 10:51:35 [notice] 71419#4269912: signal 23 (SIGIO) received from 71427
2019/06/13 10:51:37 [error] 71425#4269920: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:517):2: module 'resty.redis_iresty' not found:
	no field package.preload['resty.redis_iresty']
	no file '/Users/maliao/openresty-test//lua/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.lua'
	no file './resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.so'
	no file './resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
coroutine 0:
	[C]: in function 'require'
	content_by_lua(nginx.conf:517):2: in main chunk, client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:51:38 [error] 71427#4269922: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:517):2: module 'resty.redis_iresty' not found:
	no field package.preload['resty.redis_iresty']
	no file '/Users/maliao/openresty-test//lua/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.lua'
	no file './resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.so'
	no file './resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
coroutine 0:
	[C]: in function 'require'
	content_by_lua(nginx.conf:517):2: in main chunk, client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:51:41 [error] 71427#4269922: *3 "/Users/maliao/openresty-test/html/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: , request: "GET / HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:51:41 [info] 71427#4269922: *3 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 10:53:33 [error] 71427#4269922: *4 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:517):2: module 'resty.redis_iresty' not found:
	no field package.preload['resty.redis_iresty']
	no file '/Users/maliao/openresty-test//lua/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.lua'
	no file './resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.so'
	no file './resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
coroutine 0:
	[C]: in function 'require'
	content_by_lua(nginx.conf:517):2: in main chunk, client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:53:35 [notice] 71866#4272410: using the "kqueue" event method
2019/06/13 10:53:35 [notice] 71866#4272410: openresty/1.15.8.1
2019/06/13 10:53:35 [notice] 71866#4272410: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 10:53:35 [notice] 71866#4272410: OS: Darwin 18.6.0
2019/06/13 10:53:35 [notice] 71866#4272410: hw.ncpu: 8
2019/06/13 10:53:35 [notice] 71866#4272410: net.inet.tcp.sendspace: 131072
2019/06/13 10:53:35 [notice] 71866#4272410: kern.ipc.somaxconn: 128
2019/06/13 10:53:35 [notice] 71866#4272410: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 10:53:35 [notice] 71867#4272412: start worker processes
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71868
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71869
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71870
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71871
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71872
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71873
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71874
2019/06/13 10:53:35 [notice] 71867#4272412: start worker process 71876
2019/06/13 10:53:35 [notice] 71867#4272412: signal 23 (SIGIO) received
2019/06/13 10:53:35 [notice] 71867#4272412: signal 23 (SIGIO) received from 71874
2019/06/13 10:53:36 [error] 71873#4272418: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:517):2: module 'resty.redis_iresty' not found:
	no field package.preload['resty.redis_iresty']
	no file '/Users/maliao/openresty-test//lua/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.lua'
	no file './resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.so'
	no file './resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
coroutine 0:
	[C]: in function 'require'
	content_by_lua(nginx.conf:517):2: in main chunk, client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:53:38 [error] 71868#4272413: *2 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:517):2: module 'resty.redis_iresty' not found:
	no field package.preload['resty.redis_iresty']
	no file '/Users/maliao/openresty-test//lua/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.ljbc'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty/init.lua'
	no file './resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/luajit-2.1.0-beta3/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/share/lua/5.1/resty/redis_iresty/init.lua'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty/redis_iresty.so'
	no file './resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty/redis_iresty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/site/lualib/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/lualib/resty.so'
	no file './resty.so'
	no file '/usr/local/lib/lua/5.1/resty.so'
	no file '/usr/local/Cellar/openresty/1.15.8.1/luajit/lib/lua/5.1/resty.so'
	no file '/usr/local/lib/lua/5.1/loadall.so'
stack traceback:
coroutine 0:
	[C]: in function 'require'
	content_by_lua(nginx.conf:517):2: in main chunk, client: 127.0.0.1, server: , request: "GET /test HTTP/1.1", host: "127.0.0.1:96"
2019/06/13 10:55:21 [notice] 72140#4273994: using the "kqueue" event method
2019/06/13 10:55:21 [notice] 72140#4273994: openresty/1.15.8.1
2019/06/13 10:55:21 [notice] 72140#4273994: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 10:55:21 [notice] 72140#4273994: OS: Darwin 18.6.0
2019/06/13 10:55:21 [notice] 72140#4273994: hw.ncpu: 8
2019/06/13 10:55:21 [notice] 72140#4273994: net.inet.tcp.sendspace: 131072
2019/06/13 10:55:21 [notice] 72140#4273994: kern.ipc.somaxconn: 128
2019/06/13 10:55:21 [notice] 72140#4273994: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 10:55:21 [notice] 72141#4273995: start worker processes
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72142
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72143
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72144
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72145
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72146
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72147
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72149
2019/06/13 10:55:21 [notice] 72141#4273995: start worker process 72150
2019/06/13 10:55:21 [notice] 72141#4273995: signal 23 (SIGIO) received
2019/06/13 10:55:21 [notice] 72141#4273995: signal 23 (SIGIO) received from 72146
2019/06/13 10:55:21 [notice] 72141#4273995: signal 23 (SIGIO) received
2019/06/13 10:55:21 [notice] 72141#4273995: signal 23 (SIGIO) received from 72147
2019/06/13 10:55:21 [notice] 72141#4273995: signal 23 (SIGIO) received from 72149
2019/06/13 10:55:22 [info] 72150#4274004: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 10:55:23 [info] 72150#4274004: *3 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 10:55:24 [info] 72142#4273996: *4 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 12:05:45 [notice] 72876#4351996: using the "kqueue" event method
2019/06/13 12:05:45 [notice] 72876#4351996: openresty/1.15.8.1
2019/06/13 12:05:45 [notice] 72876#4351996: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 12:05:45 [notice] 72876#4351996: OS: Darwin 18.6.0
2019/06/13 12:05:45 [notice] 72876#4351996: hw.ncpu: 8
2019/06/13 12:05:45 [notice] 72876#4351996: net.inet.tcp.sendspace: 131072
2019/06/13 12:05:45 [notice] 72876#4351996: kern.ipc.somaxconn: 128
2019/06/13 12:05:45 [notice] 72876#4351996: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 12:05:45 [notice] 72877#4352008: start worker processes
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72878
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72879
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72880
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72881
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72882
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72883
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72884
2019/06/13 12:05:45 [notice] 72877#4352008: start worker process 72886
2019/06/13 12:05:45 [notice] 72877#4352008: signal 23 (SIGIO) received
2019/06/13 12:05:45 [notice] 72877#4352008: signal 23 (SIGIO) received
2019/06/13 12:05:45 [notice] 72877#4352008: signal 23 (SIGIO) received from 72883
2019/06/13 12:05:45 [notice] 72877#4352008: signal 23 (SIGIO) received
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] set_by_lua:2: set_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] rewrite_by_lua(nginx.conf:530):2: rewrite_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] access_by_lua(nginx.conf:533):2: access_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] content_by_lua(nginx.conf:536):2: content_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] header_filter_by_lua:2: header_filter_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] body_filter_by_lua:2: body_filter_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [error] 72886#4352016: *1 [lua] log_by_lua(nginx.conf:545):2: log_by_lua* while logging request, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 12:05:56 [info] 72886#4352016: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
2019/06/13 13:32:01 [notice] 73559#4410172: using the "kqueue" event method
2019/06/13 13:32:01 [notice] 73559#4410172: openresty/1.15.8.1
2019/06/13 13:32:01 [notice] 73559#4410172: built by clang 10.0.1 (clang-1001.0.46.4)
2019/06/13 13:32:01 [notice] 73559#4410172: OS: Darwin 18.6.0
2019/06/13 13:32:01 [notice] 73559#4410172: hw.ncpu: 8
2019/06/13 13:32:01 [notice] 73559#4410172: net.inet.tcp.sendspace: 131072
2019/06/13 13:32:01 [notice] 73559#4410172: kern.ipc.somaxconn: 128
2019/06/13 13:32:01 [notice] 73559#4410172: getrlimit(RLIMIT_NOFILE): 7168:9223372036854775807
2019/06/13 13:32:01 [notice] 73560#4410174: start worker processes
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73561
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73562
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73563
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73564
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73565
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73566
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73568
2019/06/13 13:32:01 [notice] 73560#4410174: start worker process 73569
2019/06/13 13:32:01 [notice] 73560#4410174: signal 23 (SIGIO) received
2019/06/13 13:32:01 [notice] 73560#4410174: signal 23 (SIGIO) received from 73566
2019/06/13 13:32:01 [notice] 73560#4410174: signal 23 (SIGIO) received from 73568
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] set_by_lua:2: set_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] rewrite_by_lua(nginx.conf:545):2: rewrite_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] access_by_lua(nginx.conf:548):2: access_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] content_by_lua(nginx.conf:528):2: content_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] header_filter_by_lua:2: header_filter_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] body_filter_by_lua:2: body_filter_by_lua*, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [error] 73569#4410183: *1 [lua] log_by_lua(nginx.conf:537):2: log_by_lua* while logging request, client: 127.0.0.1, server: , request: "GET /mixed HTTP/1.1", host: "127.0.0.1:97"
2019/06/13 13:32:03 [info] 73569#4410183: *1 kevent() reported that client 127.0.0.1 closed keepalive connection
